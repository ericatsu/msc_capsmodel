{"cells":[{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":401},"executionInfo":{"elapsed":412,"status":"error","timestamp":1712163846563,"user":{"displayName":"Eric Atsu","userId":"07034272450564729813"},"user_tz":0},"id":"CWzclXTH3tmL","outputId":"cfdc528d-7375-4b7b-cd39-cf2b755d76cb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 5711 images belonging to 4 classes.\n","Found 1311 images belonging to 4 classes.\n"]}],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import numpy as np\n","from sklearn.utils.class_weight import compute_class_weight\n","from tensorflow.keras import layers, models, Input\n","from capsule_layers import CapsuleLayer, Mask, margin_loss, squash\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from PIL import Image\n","import os\n","import tensorflow as tf\n","\n","\n","train_dir = './dataset/training'\n","test_dir = './dataset/testing'\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,  \n","    rotation_range=15,  \n","    width_shift_range=0.1,  \n","    height_shift_range=0.1,  \n","    shear_range=0.1,  \n","    zoom_range=0.1,  \n","    horizontal_flip=True,  \n","    fill_mode='nearest'  \n",")\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=(128, 128),  \n","    batch_size=32,\n","    class_mode='categorical',  \n","    color_mode='grayscale' \n",")\n","\n","validation_generator = test_datagen.flow_from_directory(\n","    test_dir,\n","    target_size=(128, 128),\n","    batch_size=32,\n","    class_mode='categorical',\n","    color_mode='grayscale'\n",")"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["# class weights to handle imbalanced data\n","class_weights = compute_class_weight(\n","    'balanced',\n","    classes=np.unique(train_generator.classes),\n","    y=train_generator.classes\n",")\n","class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n","\n","# Dataset Preparation\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Adjusting CapsNet Architecture for Detection\n","##### Capsule Network Design"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["def CapsNet(input_shape, n_classes, routings):\n","    x = layers.Input(shape=input_shape)\n","\n","    # Conv layer\n","    conv1 = layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu')(x)\n","    conv1 = layers.BatchNormalization()(conv1)\n","    \n","    # PrimaryCaps layer\n","    primarycaps = CapsuleLayer(num_capsule=32, dim_capsule=8, routings=1)(conv1)\n","\n","    # DigitCaps layer\n","    digitcaps = CapsuleLayer(num_capsule=n_classes, dim_capsule=16, routings=routings, name='digitcaps')(primarycaps)\n","\n","    # Decoder network\n","    y = layers.Input(shape=(n_classes,))\n","    masked = Mask()([digitcaps, y])\n","    \n","    # Flatten the masked output before feeding into the decoder\n","    flattened = layers.Flatten()(masked)\n","\n","    decoder = models.Sequential([\n","        layers.Dense(512, activation='relu', input_dim=n_classes * 16),  # Adjusted input dimension\n","        layers.Dense(1024, activation='relu'),\n","        layers.Dense(np.prod(input_shape), activation='sigmoid'),\n","        layers.Reshape(target_shape=input_shape)\n","    ], name='decoder')\n","\n","    decoded = decoder(flattened)\n","\n","    model = models.Model([x, y], [digitcaps, decoded])\n","    model.compile(optimizer='adam',\n","                  loss=[margin_loss, 'mse'],\n","                  loss_weights=[1., 0.392],\n","                  metrics={'capsnet': 'accuracy'})\n","\n","    return model\n"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Lester\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"functional_8\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,992</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n","│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ capsule_layer_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> │ batch_normalizat… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CapsuleLayer</span>)      │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ digitcaps           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ capsule_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CapsuleLayer</span>)      │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ input_layer_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ mask_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Mask</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ digitcaps[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n","│                     │                   │            │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ mask_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ decoder             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">17,352,192</span> │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m,  │     \u001b[38;5;34m20,992\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m]… │\n","│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m,  │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ capsule_layer_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m8\u001b[0m)     │     \u001b[38;5;34m65,536\u001b[0m │ batch_normalizat… │\n","│ (\u001b[38;5;33mCapsuleLayer\u001b[0m)      │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ digitcaps           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │        \u001b[38;5;34m512\u001b[0m │ capsule_layer_2[\u001b[38;5;34m…\u001b[0m │\n","│ (\u001b[38;5;33mCapsuleLayer\u001b[0m)      │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ input_layer_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ mask_2 (\u001b[38;5;33mMask\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ digitcaps[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n","│                     │                   │            │ input_layer_7[\u001b[38;5;34m0\u001b[0m]… │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ mask_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ decoder             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │ \u001b[38;5;34m17,352,192\u001b[0m │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","│ (\u001b[38;5;33mSequential\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,440,256</span> (66.53 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,440,256\u001b[0m (66.53 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,439,744</span> (66.53 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,439,744\u001b[0m (66.53 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["None\n"]}],"source":["input_shape = (128, 128, 1)  \n","n_classes = 4  \n","routings = 3  \n","\n","model = CapsNet(input_shape, n_classes, routings)\n","print(model.summary())\n","\n","epochs = 50 "]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["callbacks = [\n","    EarlyStopping(monitor='val_loss', patience=10, verbose=1),\n","    ModelCheckpoint('best_model.keras', monitor='val_accuracy', save_best_only=True, verbose=1)\n","]"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["def load_images_and_labels(base_dir, target_size=(128, 128)):\n","    images = []\n","    labels = []\n","    label_map = {}  # Maps folder names to numerical labels\n","\n","    # Assuming subdirectories in the base directory are class labels\n","    for label_id, subdir in enumerate(sorted(os.listdir(base_dir))):\n","        current_dir = os.path.join(base_dir, subdir)\n","        label_map[subdir] = label_id\n","        for filename in os.listdir(current_dir):\n","            img_path = os.path.join(current_dir, filename)\n","            try:\n","                with Image.open(img_path) as img:\n","                    img = img.convert('L')  # Convert to grayscale\n","                    img = img.resize(target_size)  # Resize image\n","                    img_array = np.array(img) / 255.0  # Normalize the image\n","                    images.append(img_array)\n","                    labels.append(label_id)\n","            except IOError:\n","                print(f\"Error opening image file {img_path}. Skipping...\")\n","\n","    images = np.array(images).reshape(-1, 128, 128, 1)  # Reshape for the model\n","    labels = np.array(labels)\n","    return images, labels, label_map\n","\n","# Example usage\n","train_images, train_labels, train_label_map = load_images_and_labels('./dataset/training')\n"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["def custom_generator_with_sample_weights(generator, class_weights):\n","    for x_batch, y_batch in generator:\n","        sample_weights = np.array([class_weights[np.argmax(y)] for y in y_batch])\n","        yield ([x_batch, y_batch], y_batch, sample_weights)\n","\n","# Map class indices to weights\n","class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n","\n","# Wrap the generators\n","train_gen_wrapper = custom_generator_with_sample_weights(train_generator, class_weights_dict)\n","validation_gen_wrapper = custom_generator_with_sample_weights(validation_generator, class_weights_dict)\n","\n","\n","def make_dataset(generator):\n","    return tf.data.Dataset.from_generator(\n","        lambda: generator,\n","        output_signature=(\n","            (\n","                tf.TensorSpec(shape=(None, 128, 128, 1), dtype=tf.float32),  # Image batch\n","                tf.TensorSpec(shape=(None, 4), dtype=tf.float32)  # Labels\n","            ),\n","            tf.TensorSpec(shape=(None, 4), dtype=tf.float32),  # Labels again\n","            tf.TensorSpec(shape=(None,), dtype=tf.float32)  # Sample weights\n","        )\n","    )\n","\n","train_dataset = make_dataset(train_gen_wrapper)\n","validation_dataset = make_dataset(validation_gen_wrapper)\n"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n"]},{"ename":"ValueError","evalue":"Exception encountered when calling CapsuleLayer.call().\n\n\u001b[1mShape must be rank 5 but is rank 3 for '{{node functional_8_1/capsule_layer_2_1/Tile}} = Tile[T=DT_FLOAT, Tmultiples=DT_INT32](functional_8_1/capsule_layer_2_1/ExpandDims, functional_8_1/capsule_layer_2_1/Tile/multiples)' with input shapes: [?,1,120,120,256], [3].\u001b[0m\n\nArguments received by CapsuleLayer.call():\n  • inputs=tf.Tensor(shape=(None, 120, 120, 256), dtype=float32)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\Lester\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[1;32mc:\\Users\\Lester\\Desktop\\masters\\Research\\msc_capsmodel\\capsule_layers.py:24\u001b[0m, in \u001b[0;36mCapsuleLayer.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Expand the input tensor and compute predictions\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     inputs_expand \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(inputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m     inputs_tiled \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtile\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_expand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_capsule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     inputs_transformed \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(tf\u001b[38;5;241m.\u001b[39mmatmul(inputs_tiled, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel), [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_capsule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim_capsule])\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# Initialize raw routing weights with zeros\u001b[39;00m\n","\u001b[1;31mValueError\u001b[0m: Exception encountered when calling CapsuleLayer.call().\n\n\u001b[1mShape must be rank 5 but is rank 3 for '{{node functional_8_1/capsule_layer_2_1/Tile}} = Tile[T=DT_FLOAT, Tmultiples=DT_INT32](functional_8_1/capsule_layer_2_1/ExpandDims, functional_8_1/capsule_layer_2_1/Tile/multiples)' with input shapes: [?,1,120,120,256], [3].\u001b[0m\n\nArguments received by CapsuleLayer.call():\n  • inputs=tf.Tensor(shape=(None, 120, 120, 256), dtype=float32)"]}],"source":["history = model.fit(\n","    train_dataset,\n","    steps_per_epoch=len(train_generator),\n","    validation_data=validation_dataset,\n","    validation_steps=len(validation_generator),\n","    epochs=50,\n","    callbacks=callbacks,\n","    verbose=2\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNZz+OHD7BFZIZihQ7ktULP","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
