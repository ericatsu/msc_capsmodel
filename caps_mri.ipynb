{"cells":[{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":401},"executionInfo":{"elapsed":412,"status":"error","timestamp":1712163846563,"user":{"displayName":"Eric Atsu","userId":"07034272450564729813"},"user_tz":0},"id":"CWzclXTH3tmL","outputId":"cfdc528d-7375-4b7b-cd39-cf2b755d76cb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 5711 images belonging to 4 classes.\n","Found 1311 images belonging to 4 classes.\n"]}],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import numpy as np\n","from sklearn.utils.class_weight import compute_class_weight\n","from tensorflow.keras import layers, models, Input\n","from capsule_layers import CapsuleLayer, Mask, margin_loss, squash\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from PIL import Image\n","import os\n","\n","\n","train_dir = './dataset/training'\n","test_dir = './dataset/testing'\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,  \n","    rotation_range=15,  \n","    width_shift_range=0.1,  \n","    height_shift_range=0.1,  \n","    shear_range=0.1,  \n","    zoom_range=0.1,  \n","    horizontal_flip=True,  \n","    fill_mode='nearest'  \n",")\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=(128, 128),  \n","    batch_size=32,\n","    class_mode='categorical',  \n","    color_mode='grayscale' \n",")\n","\n","validation_generator = test_datagen.flow_from_directory(\n","    test_dir,\n","    target_size=(128, 128),\n","    batch_size=32,\n","    class_mode='categorical',\n","    color_mode='grayscale'\n",")"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["# class weights to handle imbalanced data\n","class_weights = compute_class_weight(\n","    'balanced',\n","    classes=np.unique(train_generator.classes),\n","    y=train_generator.classes\n",")\n","class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n","\n","# Dataset Preparation\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Adjusting CapsNet Architecture for Detection\n","##### Capsule Network Design"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["def CapsNet(input_shape, n_classes, routings):\n","    x = layers.Input(shape=input_shape)\n","\n","    # Conv layer\n","    conv1 = layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu')(x)\n","    conv1 = layers.BatchNormalization()(conv1)\n","    \n","    # PrimaryCaps layer\n","    primarycaps = CapsuleLayer(num_capsule=32, dim_capsule=8, routings=1)(conv1)\n","\n","    # DigitCaps layer\n","    digitcaps = CapsuleLayer(num_capsule=n_classes, dim_capsule=16, routings=routings, name='digitcaps')(primarycaps)\n","\n","    # Decoder network\n","    y = layers.Input(shape=(n_classes,))\n","    masked = Mask()([digitcaps, y])\n","    \n","    # Flatten the masked output before feeding into the decoder\n","    flattened = layers.Flatten()(masked)\n","\n","    decoder = models.Sequential([\n","        layers.Dense(512, activation='relu', input_dim=n_classes * 16),  # Adjusted input dimension\n","        layers.Dense(1024, activation='relu'),\n","        layers.Dense(np.prod(input_shape), activation='sigmoid'),\n","        layers.Reshape(target_shape=input_shape)\n","    ], name='decoder')\n","\n","    decoded = decoder(flattened)\n","\n","    model = models.Model([x, y], [digitcaps, decoded])\n","    model.compile(optimizer='adam',\n","                  loss=[margin_loss, 'mse'],\n","                  loss_weights=[1., 0.392],\n","                  metrics={'capsnet': 'accuracy'})\n","\n","    return model\n"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Lester\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_20\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"functional_20\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer_15      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,992</span> │ input_layer_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n","│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ capsule_layer_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> │ batch_normalizat… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CapsuleLayer</span>)      │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ digitcaps           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ capsule_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CapsuleLayer</span>)      │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ input_layer_16      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ mask_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Mask</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ digitcaps[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n","│                     │                   │            │ input_layer_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ mask_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ decoder             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">17,352,192</span> │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer_15      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m,  │     \u001b[38;5;34m20,992\u001b[0m │ input_layer_15[\u001b[38;5;34m0\u001b[0m… │\n","│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m,  │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ capsule_layer_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m8\u001b[0m)     │     \u001b[38;5;34m65,536\u001b[0m │ batch_normalizat… │\n","│ (\u001b[38;5;33mCapsuleLayer\u001b[0m)      │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ digitcaps           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │        \u001b[38;5;34m512\u001b[0m │ capsule_layer_5[\u001b[38;5;34m…\u001b[0m │\n","│ (\u001b[38;5;33mCapsuleLayer\u001b[0m)      │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ input_layer_16      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ mask_5 (\u001b[38;5;33mMask\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ digitcaps[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n","│                     │                   │            │ input_layer_16[\u001b[38;5;34m0\u001b[0m… │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ mask_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ decoder             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │ \u001b[38;5;34m17,352,192\u001b[0m │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","│ (\u001b[38;5;33mSequential\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,440,256</span> (66.53 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,440,256\u001b[0m (66.53 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,439,744</span> (66.53 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,439,744\u001b[0m (66.53 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["None\n"]}],"source":["input_shape = (128, 128, 1)  \n","n_classes = 4  \n","routings = 3  \n","\n","model = CapsNet(input_shape, n_classes, routings)\n","print(model.summary())\n","\n","epochs = 50 "]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":["callbacks = [\n","    EarlyStopping(monitor='val_loss', patience=10, verbose=1),\n","    ModelCheckpoint('best_model.keras', monitor='val_accuracy', save_best_only=True, verbose=1)\n","]"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["import numpy as np\n","from PIL import Image\n","import os\n","\n","def load_images_and_labels(base_dir, target_size=(128, 128)):\n","    images = []\n","    labels = []\n","    label_map = {}  # Maps folder names to numerical labels\n","\n","    # Assuming subdirectories in the base directory are class labels\n","    for label_id, subdir in enumerate(sorted(os.listdir(base_dir))):\n","        current_dir = os.path.join(base_dir, subdir)\n","        label_map[subdir] = label_id\n","        for filename in os.listdir(current_dir):\n","            img_path = os.path.join(current_dir, filename)\n","            try:\n","                with Image.open(img_path) as img:\n","                    img = img.convert('L')  # Convert to grayscale\n","                    img = img.resize(target_size)  # Resize image\n","                    img_array = np.array(img) / 255.0  # Normalize the image\n","                    images.append(img_array)\n","                    labels.append(label_id)\n","            except IOError:\n","                print(f\"Error opening image file {img_path}. Skipping...\")\n","\n","    images = np.array(images).reshape(-1, 128, 128, 1)  # Reshape for the model\n","    labels = np.array(labels)\n","    return images, labels, label_map\n","\n","# Example usage\n","train_images, train_labels, train_label_map = load_images_and_labels('./dataset/training')\n"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["from PIL import Image\n","img = Image.open('./dataset/training/glioma/Tr-glTr_0002.jpg')\n","img.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNZz+OHD7BFZIZihQ7ktULP","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
